{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all keras import go here and base model is built for  image of size 224x224x3 using weights from imagenet\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "try:\n",
    "    import h5py\n",
    "except ImportError:\n",
    "    h5py = None\n",
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add layers, dropouts,batch normalization here,using adam as optimizer here\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "add_model_batch_dropout = Sequential()\n",
    "add_model_batch_dropout.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model_batch_dropout.add(Dense(512, activation='relu'))\n",
    "add_model_batch_dropout.add(BatchNormalization())\n",
    "add_model_batch_dropout.add(Dropout(0.2))\n",
    "add_model_batch_dropout.add(Dense(256, activation='relu'))\n",
    "add_model_batch_dropout.add(BatchNormalization())\n",
    "add_model_batch_dropout.add(Dropout(0.3))\n",
    "add_model_batch_dropout.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_batch_dropout = Model(inputs=base_model.input, outputs=add_model_batch_dropout(base_model.output))\n",
    "model_batch_dropout.compile(loss='binary_crossentropy', optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_batch_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define epochs early stopping(not used in actual model,used for experiment)\n",
    "from keras.callbacks import EarlyStopping\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "      \n",
    "# autosave best Model\n",
    "best_model = ModelCheckpoint('batch_normalized_weights.h5', monitor='val_acc', verbose = 1, save_best_only = True)\n",
    "\n",
    "#save model history to track accuracy and loss\n",
    "history2 = model_batch_dropout.fit(x_train, y_train, batch_size=batch_size,nb_epoch=epochs,\n",
    "              validation_data=(x_test, y_test),shuffle=True,callbacks = [best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save predictions from the model\n",
    "predictions2 = model_batch_dropout.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history2.history['acc']); plt.plot(history2.history['val_acc']);\n",
    "plt.title('model accuracy'); plt.ylabel('accuracy');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history2.history['loss']); plt.plot(history2.history['val_loss']);\n",
    "plt.title('model loss'); plt.ylabel('loss');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "plt.savefig('dropout_batch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submit to csv for kaggle score\n",
    "sample_submission3 = pd.read_csv(\"sample_submission.csv\")\n",
    "for i, name in enumerate(test_names):\n",
    "    sample_submission3.loc[sample_submission3['name'] == name, 'invasive'] = predictions2[i]\n",
    "\n",
    "sample_submission3.to_csv(\"submit_batch_drop.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
